"""
Flask –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π
–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–æ—Ç–æ, –º–æ–¥–µ–ª—å –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –µ—Å—Ç—å –ª–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è
"""

import os
import torch
import torchvision
import torch.nn as nn
from torchvision import transforms
from PIL import Image
from flask import Flask, request, render_template, jsonify, redirect, url_for
import uuid
from werkzeug.utils import secure_filename

app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['MAX_CONTENT_LENGTH'] = 10 * 1024 * 1024  # 10MB max file size

# –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –∑–∞–≥—Ä—É–∑–æ–∫
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏
model = None
device = None
transform = None

def is_model_loaded():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –ª–∏ –º–æ–¥–µ–ª—å"""
    return model is not None and device is not None and transform is not None

def load_model():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
    global model, device, transform
    
    try:
        # –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
        
        # –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
        model_path = 'prepared/best_model.pth'
        
        print(f"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª—å –ø–æ –ø—É—Ç–∏: {model_path}")
        print(f"üìÅ –¢–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {os.getcwd()}")
        print(f"üìÅ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ prepared/: {os.listdir('prepared') if os.path.exists('prepared') else '–ü–∞–ø–∫–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç'}")
        
        if not os.path.exists(model_path):
            print(f"‚ùå –û—à–∏–±–∫–∞: –ú–æ–¥–µ–ª—å {model_path} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
            return False
        
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å —Å —Ç–æ–π –∂–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π
        model = torchvision.models.resnet18(pretrained=False)
        model.fc = nn.Linear(model.fc.in_features, 2)  # 2 –∫–ª–∞—Å—Å–∞: –ø–æ–≤—Ä–µ–∂–¥–µ–Ω/–Ω–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
        model.load_state_dict(torch.load(model_path, map_location=device))
        model.to(device)
        model.eval()
        
        # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏
        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        
        print("–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
        return True
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏: {e}")
        return False

def predict_image(image_path):
    """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    global model, device, transform
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image = Image.open(image_path).convert('RGB')
        image_tensor = transform(image).unsqueeze(0)  # –î–æ–±–∞–≤–ª—è–µ–º batch dimension
        image_tensor = image_tensor.to(device)
        
        # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        with torch.no_grad():
            outputs = model(image_tensor)
            probabilities = torch.softmax(outputs, dim=1)
            predicted_class = torch.argmax(outputs, dim=1).item()
            confidence = probabilities[0][predicted_class].item()
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç
        class_names = ['–ù–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω', '–ü–æ–≤—Ä–µ–∂–¥–µ–Ω']
        result = {
            'prediction': class_names[predicted_class],
            'confidence': confidence,
            'probabilities': {
                'no_damage': probabilities[0][0].item(),
                'damage': probabilities[0][1].item()
            }
        }
        
        return result, None
        
    except Exception as e:
        return None, str(e)

@app.route('/')
def index():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞"""
    return render_template('index.html')

@app.route('/upload', methods=['POST'])
def upload_file():
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
    if 'file' not in request.files:
        return jsonify({'error': '–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω'}), 400
    
    file = request.files['file']
    
    if file.filename == '':
        return jsonify({'error': '–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω'}), 400
    
    if file and allowed_file(file.filename):
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
        filename = secure_filename(file.filename)
        unique_filename = f"{uuid.uuid4()}_{filename}"
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], unique_filename)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
        file.save(filepath)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        if not is_model_loaded():
            print(f"‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞! model={model is not None}, device={device is not None}, transform={transform is not None}")
            return jsonify({'error': '–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–µ—Ä–≤–µ—Ä.'}), 500
        
        result, error = predict_image(filepath)
        
        if error:
            # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª –ø—Ä–∏ –æ—à–∏–±–∫–µ
            os.remove(filepath)
            return jsonify({'error': f'–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {error}'}), 500
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        os.remove(filepath)
        
        return jsonify(result)
    
    return jsonify({'error': '–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞'}), 400

def allowed_file(filename):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤"""
    ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif', 'bmp', 'webp', 'tiff', 'tif'}
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

@app.route('/health')
def health():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    return jsonify({
        'status': 'ok',
        'model_loaded': is_model_loaded(),
        'device': str(device) if device else None
    })

@app.route('/model_status')
def model_status():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –º–æ–¥–µ–ª–∏"""
    return jsonify({
        'model_loaded': is_model_loaded(),
        'model_exists': os.path.exists('prepared/best_model.pth'),
        'device': str(device) if device else None,
        'current_dir': os.getcwd(),
        'prepared_dir_exists': os.path.exists('prepared'),
        'prepared_contents': os.listdir('prepared') if os.path.exists('prepared') else [],
        'model_vars': {
            'model': model is not None,
            'device': device is not None,
            'transform': transform is not None
        }
    })

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ –º–æ–¥—É–ª—è
print("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å...")
if load_model():
    print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏")
else:
    print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏")

if __name__ == '__main__':
    print("–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å...")
    if load_model():
        print("–ó–∞–ø—É—Å–∫–∞–µ–º –≤–µ–±-—Å–µ—Ä–≤–µ—Ä...")
        app.run(debug=True, host='0.0.0.0', port=5000)
    else:
        print("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –º–æ–¥–µ–ª–∏.")
